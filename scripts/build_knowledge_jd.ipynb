{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skillExtracter import extractKeywordFromLightSkillAPI\n",
    "import json\n",
    "from util import getAccessToken\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/job_descriptions/jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = json.loads(getAccessToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(1.1) == type(2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row.description is pd.isnull or row.description == None or pd.isna(row.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "chunksize = 1000\n",
    "for chunk in pd.read_csv('data/job_descriptions/jobs.csv', chunksize=chunksize):\n",
    "    print(\"processing 1000 record\")\n",
    "    for row in chunk.itertuples(index=False):\n",
    "        if pd.isna(row.description):\n",
    "            continue\n",
    "        job = {}\n",
    "        job['description'] = row.description\n",
    "        job['Industries'] = row.Industries\n",
    "        job['company'] = row.company\n",
    "        job['context'] = row.context\n",
    "        job['education'] = row.education\n",
    "        job['location'] = row.location\n",
    "        job['months_experience'] = row.months_experience\n",
    "        job['sal_high'] = row.sal_high\n",
    "        job['sal_low'] = row.sal_low\n",
    "        job['salary'] = row.salary\n",
    "        job['title'] = row.title\n",
    "        skills = extractKeywordFromLightSkillAPI(row.description, token)     \n",
    "        job['skills'] = \",\".join(skills)\n",
    "        data.append(job)\n",
    "    print('processed 1000 data')\n",
    "\n",
    "newdf = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv(\"jd_with_keyword.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/job_descriptions/jd_with_keyword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>Industries</th>\n",
       "      <th>company</th>\n",
       "      <th>context</th>\n",
       "      <th>education</th>\n",
       "      <th>location</th>\n",
       "      <th>months_experience</th>\n",
       "      <th>sal_high</th>\n",
       "      <th>sal_low</th>\n",
       "      <th>salary</th>\n",
       "      <th>title</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Job Title: Senior Data Engineer Location: Alex...</td>\n",
       "      <td>Broadcast Media</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>NoSQL,Agile Methodology,Unit Testing,Data Proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ethicon, part of Johnson &amp; Johnson Medical Dev...</td>\n",
       "      <td>Hospital &amp; Health Care, Medical Devices, and P...</td>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Principal Full Stack Software Engineer.</td>\n",
       "      <td>Angular (Web Framework),Software Configuration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft’s WCB health team is looking for a S...</td>\n",
       "      <td>Computer Hardware, Computer Software, and Info...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>84.0</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>$120,000.00/yr - $189,000.00/yr</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Microsoft Azure,Concision,Debugging,Database A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Microsoft’s WCB health team is looking for a S...</td>\n",
       "      <td>Computer Hardware, Computer Software, and Info...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Reston, VA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>$120,000.00/yr - $189,000.00/yr</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Microsoft Azure,Concision,Debugging,Database A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Microsoft’s WCB health team is looking for a S...</td>\n",
       "      <td>Computer Hardware, Computer Software, and Info...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>84.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>$108,000.00/yr - $175,000.00/yr</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>Microsoft Azure,Concision,Debugging,Database A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>7775</td>\n",
       "      <td>Who We Are: The Oracle's State &amp; Local Global ...</td>\n",
       "      <td>Information Technology and Services, Computer ...</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>United States</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Site Reliability Engineer</td>\n",
       "      <td>Kibana,C++ (Programming Language),Fault Tolera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>7776</td>\n",
       "      <td>Primary Skills: 1. Good hands on experience on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sky Solutions</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Malvern, PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Site Reliability Engineer</td>\n",
       "      <td>Spring Boot,Github,Kubernetes,RESTful API,Apac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>7777</td>\n",
       "      <td>About The Team The SRE team at Zillow Group em...</td>\n",
       "      <td>Marketing and Advertising, Computer Software, ...</td>\n",
       "      <td>Zillow</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>United States</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Site Reliability Engineer</td>\n",
       "      <td>Debugging,Software Systems,Real Estate Transac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>7778</td>\n",
       "      <td>PlayStation isn’t just the Best Place to Play ...</td>\n",
       "      <td>Computer Software, Consumer Services, and Ente...</td>\n",
       "      <td>PlayStation</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>$129,000.00/yr - $162,000.00/yr</td>\n",
       "      <td>Sr. Site Reliability Engineer</td>\n",
       "      <td>Java Virtual Machine (JVM),MySQL,Cloud Infrast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7779</th>\n",
       "      <td>7779</td>\n",
       "      <td>Our Company Changing the world through digital...</td>\n",
       "      <td>Marketing and Advertising, Information Technol...</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>{\"@context\": \"http://schema.org\", \"@type\": \"Jo...</td>\n",
       "      <td>bachelor degree</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Site Reliability Engineer</td>\n",
       "      <td>NoSQL,Ruby (Programming Language),Python (Prog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7780 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                        description  \\\n",
       "0              0  Job Title: Senior Data Engineer Location: Alex...   \n",
       "1              1  Ethicon, part of Johnson & Johnson Medical Dev...   \n",
       "2              2  Microsoft’s WCB health team is looking for a S...   \n",
       "3              3  Microsoft’s WCB health team is looking for a S...   \n",
       "4              4  Microsoft’s WCB health team is looking for a S...   \n",
       "...          ...                                                ...   \n",
       "7775        7775  Who We Are: The Oracle's State & Local Global ...   \n",
       "7776        7776  Primary Skills: 1. Good hands on experience on...   \n",
       "7777        7777  About The Team The SRE team at Zillow Group em...   \n",
       "7778        7778  PlayStation isn’t just the Best Place to Play ...   \n",
       "7779        7779  Our Company Changing the world through digital...   \n",
       "\n",
       "                                             Industries            company  \\\n",
       "0                                       Broadcast Media        CyberCoders   \n",
       "1     Hospital & Health Care, Medical Devices, and P...  Johnson & Johnson   \n",
       "2     Computer Hardware, Computer Software, and Info...          Microsoft   \n",
       "3     Computer Hardware, Computer Software, and Info...          Microsoft   \n",
       "4     Computer Hardware, Computer Software, and Info...          Microsoft   \n",
       "...                                                 ...                ...   \n",
       "7775  Information Technology and Services, Computer ...             Oracle   \n",
       "7776                                                NaN      Sky Solutions   \n",
       "7777  Marketing and Advertising, Computer Software, ...             Zillow   \n",
       "7778  Computer Software, Consumer Services, and Ente...        PlayStation   \n",
       "7779  Marketing and Advertising, Information Technol...              Adobe   \n",
       "\n",
       "                                                context        education  \\\n",
       "0     {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "1     {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "2     {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "3     {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "4     {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "...                                                 ...              ...   \n",
       "7775  {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "7776  {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "7777  {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "7778  {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "7779  {\"@context\": \"http://schema.org\", \"@type\": \"Jo...  bachelor degree   \n",
       "\n",
       "             location  months_experience  sal_high   sal_low  \\\n",
       "0      Alexandria, VA               60.0       NaN       NaN   \n",
       "1     Santa Clara, CA               96.0       NaN       NaN   \n",
       "2      Washington, DC               84.0  189000.0  120000.0   \n",
       "3          Reston, VA               84.0  189000.0  120000.0   \n",
       "4          Irving, TX               84.0  175000.0  108000.0   \n",
       "...               ...                ...       ...       ...   \n",
       "7775    United States               60.0       NaN       NaN   \n",
       "7776      Malvern, PA                NaN       NaN       NaN   \n",
       "7777    United States               60.0       NaN       NaN   \n",
       "7778    San Diego, CA               84.0  162000.0  129000.0   \n",
       "7779       Austin, TX               36.0       NaN       NaN   \n",
       "\n",
       "                               salary  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2     $120,000.00/yr - $189,000.00/yr   \n",
       "3     $120,000.00/yr - $189,000.00/yr   \n",
       "4     $108,000.00/yr - $175,000.00/yr   \n",
       "...                               ...   \n",
       "7775                              NaN   \n",
       "7776                              NaN   \n",
       "7777                              NaN   \n",
       "7778  $129,000.00/yr - $162,000.00/yr   \n",
       "7779                              NaN   \n",
       "\n",
       "                                        title  \\\n",
       "0                        Senior Data Engineer   \n",
       "1     Principal Full Stack Software Engineer.   \n",
       "2                    Senior Software Engineer   \n",
       "3                    Senior Software Engineer   \n",
       "4                    Senior Software Engineer   \n",
       "...                                       ...   \n",
       "7775         Senior Site Reliability Engineer   \n",
       "7776                Site Reliability Engineer   \n",
       "7777         Senior Site Reliability Engineer   \n",
       "7778            Sr. Site Reliability Engineer   \n",
       "7779                Site Reliability Engineer   \n",
       "\n",
       "                                                 skills  \n",
       "0     NoSQL,Agile Methodology,Unit Testing,Data Proc...  \n",
       "1     Angular (Web Framework),Software Configuration...  \n",
       "2     Microsoft Azure,Concision,Debugging,Database A...  \n",
       "3     Microsoft Azure,Concision,Debugging,Database A...  \n",
       "4     Microsoft Azure,Concision,Debugging,Database A...  \n",
       "...                                                 ...  \n",
       "7775  Kibana,C++ (Programming Language),Fault Tolera...  \n",
       "7776  Spring Boot,Github,Kubernetes,RESTful API,Apac...  \n",
       "7777  Debugging,Software Systems,Real Estate Transac...  \n",
       "7778  Java Virtual Machine (JVM),MySQL,Cloud Infrast...  \n",
       "7779  NoSQL,Ruby (Programming Language),Python (Prog...  \n",
       "\n",
       "[7780 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ResourceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"None\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old code updated code is at below sale with method name createEmbeddingWithValues\n",
    "# embeddings = []\n",
    "# chunksize = 1000\n",
    "# for chunk in pd.read_csv('jd_with_keyword.csv', chunksize=chunksize):\n",
    "#     print(\"processing 1000 record\")\n",
    "#     for row in chunk.itertuples(index=False):\n",
    "#         response = client.embeddings.create(model=EMBEDDING_MODEL, input=chunk)\n",
    "#         for i, be in enumerate(response.data):\n",
    "#             assert i == be.index\n",
    "#         batch_embeddings = [e.embedding for e in response.data]\n",
    "#         embeddings.extend(batch_embeddings)\n",
    "#     print(\"processed 1000 record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmbeddingWithValues(data, extras):\n",
    "    result, __data =[], {}\n",
    "    response = client.embeddings.create(model=EMBEDDING_MODEL, input=data)\n",
    "    for i, be in enumerate(response.data):\n",
    "        assert i == be.index\n",
    "    batch_embeddings = [e.embedding for e in response.data]\n",
    "    __data[\"id\"] = str(extras['id'])\n",
    "    __data[\"values\"] = batch_embeddings[0]\n",
    "    __data[\"metadata\"] = {'extras': str(extras)}\n",
    "    result.append(__data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDic(row):\n",
    "    dic = {}\n",
    "    dic[\"id\"] = str(row._0)\n",
    "    dic[\"description\"] = str(row.description)\n",
    "    dic[\"industries\"] = \"\" if pd.isnull(row.Industries) else str(row.Industries)\n",
    "    dic[\"company\"] = \"\" if pd.isnull(row.company) else str(row.company)\n",
    "    dic[\"education\"] = \"\" if pd.isnull(row.education) else str(row.education)\n",
    "    dic[\"months_experience\"] = 0 if pd.isna(row.months_experience) else row.months_experience\n",
    "    dic[\"sal_high\"] = 0 if pd.isna(row.sal_high) else row.sal_high\n",
    "    dic[\"sal_low\"] = 0 if pd.isna(row.sal_low) else row.sal_low\n",
    "    dic[\"salary\"] = 0 if pd.isna(row.salary) else row.salary\n",
    "    dic[\"title\"] = \"\" if pd.isnull(row.title) else str(row.title)\n",
    "    dic[\"skills\"] = \"\" if pd.isnull(row.skills) else str(row.skills)\n",
    "    return dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n",
      "processing 500\n",
      "processed 500\n"
     ]
    }
   ],
   "source": [
    "description_embeddings = []\n",
    "skills_embeddings = []\n",
    "chunksize = 500\n",
    "for chunk in pd.read_csv('../data/job_descriptions/jd_with_keyword.csv', chunksize=chunksize):\n",
    "    print(\"processing 500\")\n",
    "    for row in chunk.itertuples(index=False):\n",
    "        if pd.isna(row.description) or pd.isna(row.skills):\n",
    "            continue\n",
    "        description_embeddings.extend(createEmbeddingWithValues(row.description, convertToDic(row)))\n",
    "        skills_embeddings.extend(createEmbeddingWithValues(row.skills, convertToDic(row)))\n",
    "    print(\"processed 500\")\n",
    "\n",
    "description_embeddings_df = pd.DataFrame(description_embeddings)\n",
    "skills_embeddings_df = pd.DataFrame(skills_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embeddings_df.to_csv(\"../data/embeddings/description_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_embeddings_df.to_csv(\"../data/embeddings/skills_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embeddings_df = pd.read_csv(\"../data/embeddings/description_embeddings.csv\")\n",
    "skills_embeddings_df = pd.read_csv(\"../data/embeddings/skills_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432efbce-a192-4eb1-bba7-6b46fb18f1b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aniketgiram/Desktop/Big-Data/JobFitAI/.venv/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(_api_key)\n",
    "pc = Pinecone(\n",
    "    api_key=\"432efbce-a192-4eb1-bba7-6b46fb18f1b5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_fit_index_name = 'job-fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "if job_fit_index_name in pc.list_indexes():\n",
    "    pc.delete_index(job_fit_index_name)\n",
    "\n",
    "# Now do stuff\n",
    "if job_fit_index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=job_fit_index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(job_fit_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(\n",
    "  vectors=description_embeddings,\n",
    "  namespace=\"description\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    \"\"\"Yields successive chunks from seq.\"\"\"\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq.iloc[pos:pos + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(chunk):\n",
    "    \"\"\"Converts a pandas DataFrame chunk to the format expected by Pinecone's upsert method.\"\"\"\n",
    "    data = []\n",
    "    for _, row in chunk.iterrows():\n",
    "        vector_id = str(row['id'])\n",
    "        embedding = row['values']\n",
    "        metadata = row.get('metadata', {})\n",
    "        if 'context' in eval(metadata['extras']):\n",
    "            extras = eval(metadata['extras'])\n",
    "            del extras['context']\n",
    "            metadata = extras\n",
    "        data.append((vector_id, embedding, metadata))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100  # Define your chunk size\n",
    "for chunk in chunker(description_embeddings_df, chunk_size):\n",
    "    vectors_to_upsert = convert_data(chunk)\n",
    "    print(vectors_to_upsert)\n",
    "    print(\"vectorising chunk\")\n",
    "    index.upsert(\n",
    "        vectors=vectors_to_upsert,\n",
    "        namespace=\"description\",\n",
    "    )\n",
    "    print(\"upserted chunk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n",
      "vectorising chunk\n",
      "upserted chunk\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 200  # Define your chunk size\n",
    "for chunk in chunker(skills_embeddings_df, chunk_size):\n",
    "    vectors_to_upsert = convert_data(chunk)\n",
    "    print(\"vectorising chunk\")\n",
    "    index.upsert(\n",
    "        vectors=vectors_to_upsert,\n",
    "        namespace=\"skills\"\n",
    "    )\n",
    "    print(\"upserted chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Job Title: Senior Data Engineer Location: Alexandria, VA Salary Range: $120k - $150k Requirements: ETL/ELT, SQL, AWS/Google Cloud, Linux/Unix, Spark (preferred), NoSQL (preferred), Machine Learning concepts (preferred) Based in beautiful Alexandria, VA, we are one of the hottest media analytics and software start-ups in the DC area. Due to growth, we are actively seeking to hire a Senior Data Engineer to join our team. The ideal candidate will have at least 5 years of experience with data pipelines (built with Python), ETL experience, a strong SQL background, experience with AWS or Google Cloud, and strong Unix/Linux fundamentals. Any experience with Spark, NoSQL, and Machine Learning would be a huge plus. If this sounds like you, please apply now or send your resume to shiv.warrier@cybercoders.com! What You Will Be Doing Lead design and development of data pipelines Deliver features on a cadence within an agile framework Contribute to the definition of user stories Collaborate with other members of the team, including offshore, on development integration Write unit tests and maintain high code quality, per both static code analysis team standards Be available on a rotating schedule for production issues What You Need for this Position Must-Have BS in Computer Science or equivalent 5+ years of experience in software/data engineering Expertise in ETL/ELT techniques Expertise in SQL Experience working with AWS or Google Cloud Strong Unix/Linux fundamentals Nice To Have Experience with data processing frameworks e.g. Spark Experience with NoSQL column-store databases Exposure to machine learning concepts Exposure to ad tech concepts terminology What's In It for You Competitive salary with high bonus potential Collaborative and creative atmosphere, with inspired leadership Career advancement opportunities Recognition and reward for outstanding performance Great medical, dental; vision Insurance packages Competitive 401K with company match to plan for the long term Unlimited paid-time-off Transportation benefits, cell phone reimbursement Casual dress all day, every day So, if you are a Senior Data Engineer with experience, please apply today! Email Your Resume In Word To Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also: Shiv.Warrier@CyberCoders.com Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : SW3-1634173 -- in the email subject line for your application to be considered.*** Shiv Warrier - Sr. Executive Recruiter - CyberCoders Applicants must be authorized to work in the U.S. CyberCoders, Inc is proud to be an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law. Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n",
    "\"\"\"\n",
    "\n",
    "xqq = client.embeddings.create(input=query, model=EMBEDDING_MODEL).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'description': {'vector_count': 7768},\n",
       "                'skills': {'vector_count': 7768}},\n",
       " 'total_vector_count': 15536}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_res = index.query(top_k=3, vector=xqq, namespace=\"description\", include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '1707',\n",
       "              'metadata': {'extras': '{\\'id\\': \\'1707\\', \\'description\\': \"Job '\n",
       "                                     'Title: Senior Data Engineer Location: '\n",
       "                                     'Alexandria, VA Salary Range: $120k - '\n",
       "                                     '$150k Requirements: ETL/ELT, SQL, '\n",
       "                                     'AWS/Google Cloud, Linux/Unix, Spark '\n",
       "                                     '(preferred), NoSQL (preferred), Machine '\n",
       "                                     'Learning concepts (preferred) Based in '\n",
       "                                     'beautiful Alexandria, VA, we are one of '\n",
       "                                     'the hottest media analytics and software '\n",
       "                                     'start-ups in the DC area. Due to growth, '\n",
       "                                     'we are actively seeking to hire a Senior '\n",
       "                                     'Data Engineer to join our team. The '\n",
       "                                     'ideal candidate will have at least 5 '\n",
       "                                     'years of experience with data pipelines '\n",
       "                                     '(built with Python), ETL experience, a '\n",
       "                                     'strong SQL background, experience with '\n",
       "                                     'AWS or Google Cloud, and strong '\n",
       "                                     'Unix/Linux fundamentals. Any experience '\n",
       "                                     'with Spark, NoSQL, and Machine Learning '\n",
       "                                     'would be a huge plus. If this sounds '\n",
       "                                     'like you, please apply now or send your '\n",
       "                                     'resume to shiv.warrier@cybercoders.com! '\n",
       "                                     'What You Will Be Doing Lead design and '\n",
       "                                     'development of data pipelines Deliver '\n",
       "                                     'features on a cadence within an agile '\n",
       "                                     'framework Contribute to the definition '\n",
       "                                     'of user stories Collaborate with other '\n",
       "                                     'members of the team, including offshore, '\n",
       "                                     'on development integration Write unit '\n",
       "                                     'tests and maintain high code quality, '\n",
       "                                     'per both static code analysis team '\n",
       "                                     'standards Be available on a rotating '\n",
       "                                     'schedule for production issues What You '\n",
       "                                     'Need for this Position Must-Have BS in '\n",
       "                                     'Computer Science or equivalent 5+ years '\n",
       "                                     'of experience in software/data '\n",
       "                                     'engineering Expertise in ETL/ELT '\n",
       "                                     'techniques Expertise in SQL Experience '\n",
       "                                     'working with AWS or Google Cloud Strong '\n",
       "                                     'Unix/Linux fundamentals Nice To Have '\n",
       "                                     'Experience with data processing '\n",
       "                                     'frameworks e.g. Spark Experience with '\n",
       "                                     'NoSQL column-store databases Exposure to '\n",
       "                                     'machine learning concepts Exposure to ad '\n",
       "                                     \"tech concepts terminology What's In It \"\n",
       "                                     'for You Competitive salary with high '\n",
       "                                     'bonus potential Collaborative and '\n",
       "                                     'creative atmosphere, with inspired '\n",
       "                                     'leadership Career advancement '\n",
       "                                     'opportunities Recognition and reward for '\n",
       "                                     'outstanding performance Great medical, '\n",
       "                                     'dental; vision Insurance packages '\n",
       "                                     'Competitive 401K with company match to '\n",
       "                                     'plan for the long term Unlimited '\n",
       "                                     'paid-time-off Transportation benefits, '\n",
       "                                     'cell phone reimbursement Casual dress '\n",
       "                                     'all day, every day So, if you are a '\n",
       "                                     'Senior Data Engineer with experience, '\n",
       "                                     'please apply today! Email Your Resume In '\n",
       "                                     'Word To Looking forward to receiving '\n",
       "                                     'your resume through our website and '\n",
       "                                     'going over the position with you. '\n",
       "                                     'Clicking apply is the best way to apply, '\n",
       "                                     'but you may also: '\n",
       "                                     'Shiv.Warrier@CyberCoders.com Please do '\n",
       "                                     'NOT change the email subject line in any '\n",
       "                                     'way. You must keep the JobID: linkedin : '\n",
       "                                     'SW3-1634173 -- in the email subject line '\n",
       "                                     'for your application to be '\n",
       "                                     'considered.*** Shiv Warrier - Sr. '\n",
       "                                     'Executive Recruiter - CyberCoders '\n",
       "                                     'Applicants must be authorized to work in '\n",
       "                                     'the U.S. CyberCoders, Inc is proud to be '\n",
       "                                     'an Equal Opportunity Employer All '\n",
       "                                     'qualified applicants will receive '\n",
       "                                     'consideration for employment without '\n",
       "                                     'regard to race, color, religion, sex, '\n",
       "                                     'national origin, disability, protected '\n",
       "                                     'veteran status, or any other '\n",
       "                                     'characteristic protected by law. Your '\n",
       "                                     'Right to Work - In compliance with '\n",
       "                                     'federal law, all persons hired will be '\n",
       "                                     'required to verify identity and '\n",
       "                                     'eligibility to work in the United States '\n",
       "                                     'and to complete the required employment '\n",
       "                                     'eligibility verification document form '\n",
       "                                     'upon hire.\", \\'industries\\': \\'Broadcast '\n",
       "                                     \"Media', 'company': 'CyberCoders', \"\n",
       "                                     \"'education': 'bachelor degree', \"\n",
       "                                     \"'months_experience': 60.0, 'sal_high': \"\n",
       "                                     \"0, 'sal_low': 0, 'salary': 0, 'title': \"\n",
       "                                     \"'Senior Data Engineer', 'skills': \"\n",
       "                                     \"'NoSQL,Agile Methodology,Unit \"\n",
       "                                     'Testing,Data Processing,Unix,Data '\n",
       "                                     'Engineering,Linux,Python (Programming '\n",
       "                                     'Language),Apache Spark,Machine '\n",
       "                                     'Learning,Software Quality (SQA/SQC),SQL '\n",
       "                                     '(Programming Language),Data '\n",
       "                                     'Pipelines,Amazon Web Services,Static '\n",
       "                                     'Program Analysis,Extract Transform Load '\n",
       "                                     '(ETL),Executive Recruitment,Computer '\n",
       "                                     'Science,Google Cloud Platform (GCP),User '\n",
       "                                     \"Story,Leadership'}\"},\n",
       "              'score': 0.982218087,\n",
       "              'values': []},\n",
       "             {'id': '0',\n",
       "              'metadata': {'extras': '{\\'id\\': \\'0\\', \\'description\\': \"Job '\n",
       "                                     'Title: Senior Data Engineer Location: '\n",
       "                                     'Alexandria, VA Salary Range: $120k - '\n",
       "                                     '$150k Requirements: ETL/ELT, SQL, '\n",
       "                                     'AWS/Google Cloud, Linux/Unix, Spark '\n",
       "                                     '(preferred), NoSQL (preferred), Machine '\n",
       "                                     'Learning concepts (preferred) Based in '\n",
       "                                     'beautiful Alexandria, VA, we are one of '\n",
       "                                     'the hottest media analytics and software '\n",
       "                                     'start-ups in the DC area. Due to growth, '\n",
       "                                     'we are actively seeking to hire a Senior '\n",
       "                                     'Data Engineer to join our team. The '\n",
       "                                     'ideal candidate will have at least 5 '\n",
       "                                     'years of experience with data pipelines '\n",
       "                                     '(built with Python), ETL experience, a '\n",
       "                                     'strong SQL background, experience with '\n",
       "                                     'AWS or Google Cloud, and strong '\n",
       "                                     'Unix/Linux fundamentals. Any experience '\n",
       "                                     'with Spark, NoSQL, and Machine Learning '\n",
       "                                     'would be a huge plus. If this sounds '\n",
       "                                     'like you, please apply now or send your '\n",
       "                                     'resume to shiv.warrier@cybercoders.com! '\n",
       "                                     'What You Will Be Doing Lead design and '\n",
       "                                     'development of data pipelines Deliver '\n",
       "                                     'features on a cadence within an agile '\n",
       "                                     'framework Contribute to the definition '\n",
       "                                     'of user stories Collaborate with other '\n",
       "                                     'members of the team, including offshore, '\n",
       "                                     'on development integration Write unit '\n",
       "                                     'tests and maintain high code quality, '\n",
       "                                     'per both static code analysis team '\n",
       "                                     'standards Be available on a rotating '\n",
       "                                     'schedule for production issues What You '\n",
       "                                     'Need for this Position Must-Have BS in '\n",
       "                                     'Computer Science or equivalent 5+ years '\n",
       "                                     'of experience in software/data '\n",
       "                                     'engineering Expertise in ETL/ELT '\n",
       "                                     'techniques Expertise in SQL Experience '\n",
       "                                     'working with AWS or Google Cloud Strong '\n",
       "                                     'Unix/Linux fundamentals Nice To Have '\n",
       "                                     'Experience with data processing '\n",
       "                                     'frameworks e.g. Spark Experience with '\n",
       "                                     'NoSQL column-store databases Exposure to '\n",
       "                                     'machine learning concepts Exposure to ad '\n",
       "                                     \"tech concepts terminology What's In It \"\n",
       "                                     'for You Competitive salary with high '\n",
       "                                     'bonus potential Collaborative and '\n",
       "                                     'creative atmosphere, with inspired '\n",
       "                                     'leadership Career advancement '\n",
       "                                     'opportunities Recognition and reward for '\n",
       "                                     'outstanding performance Great medical, '\n",
       "                                     'dental; vision Insurance packages '\n",
       "                                     'Competitive 401K with company match to '\n",
       "                                     'plan for the long term Unlimited '\n",
       "                                     'paid-time-off Transportation benefits, '\n",
       "                                     'cell phone reimbursement Casual dress '\n",
       "                                     'all day, every day So, if you are a '\n",
       "                                     'Senior Data Engineer with experience, '\n",
       "                                     'please apply today! Email Your Resume In '\n",
       "                                     'Word To Looking forward to receiving '\n",
       "                                     'your resume through our website and '\n",
       "                                     'going over the position with you. '\n",
       "                                     'Clicking apply is the best way to apply, '\n",
       "                                     'but you may also: '\n",
       "                                     'Shiv.Warrier@CyberCoders.com Please do '\n",
       "                                     'NOT change the email subject line in any '\n",
       "                                     'way. You must keep the JobID: linkedin : '\n",
       "                                     'SW3-1634173 -- in the email subject line '\n",
       "                                     'for your application to be '\n",
       "                                     'considered.*** Shiv Warrier - Sr. '\n",
       "                                     'Executive Recruiter - CyberCoders '\n",
       "                                     'Applicants must be authorized to work in '\n",
       "                                     'the U.S. CyberCoders, Inc is proud to be '\n",
       "                                     'an Equal Opportunity Employer All '\n",
       "                                     'qualified applicants will receive '\n",
       "                                     'consideration for employment without '\n",
       "                                     'regard to race, color, religion, sex, '\n",
       "                                     'national origin, disability, protected '\n",
       "                                     'veteran status, or any other '\n",
       "                                     'characteristic protected by law. Your '\n",
       "                                     'Right to Work - In compliance with '\n",
       "                                     'federal law, all persons hired will be '\n",
       "                                     'required to verify identity and '\n",
       "                                     'eligibility to work in the United States '\n",
       "                                     'and to complete the required employment '\n",
       "                                     'eligibility verification document form '\n",
       "                                     'upon hire.\", \\'industries\\': \\'Broadcast '\n",
       "                                     \"Media', 'company': 'CyberCoders', \"\n",
       "                                     \"'education': 'bachelor degree', \"\n",
       "                                     \"'months_experience': 60.0, 'sal_high': \"\n",
       "                                     \"0, 'sal_low': 0, 'salary': 0, 'title': \"\n",
       "                                     \"'Senior Data Engineer', 'skills': \"\n",
       "                                     \"'NoSQL,Agile Methodology,Unit \"\n",
       "                                     'Testing,Data Processing,Unix,Data '\n",
       "                                     'Engineering,Linux,Python (Programming '\n",
       "                                     'Language),Apache Spark,Machine '\n",
       "                                     'Learning,Software Quality (SQA/SQC),SQL '\n",
       "                                     '(Programming Language),Data '\n",
       "                                     'Pipelines,Amazon Web Services,Static '\n",
       "                                     'Program Analysis,Extract Transform Load '\n",
       "                                     '(ETL),Executive Recruitment,Computer '\n",
       "                                     'Science,Google Cloud Platform (GCP),User '\n",
       "                                     \"Story,Leadership'}\"},\n",
       "              'score': 0.982218087,\n",
       "              'values': []},\n",
       "             {'id': '1705',\n",
       "              'metadata': {'extras': '{\\'id\\': \\'1705\\', \\'description\\': \"Job '\n",
       "                                     'Title: Senior Data Engineer Location: '\n",
       "                                     'Alexandria, VA (Onsite 1-2 days/week) '\n",
       "                                     'Salary Range: $140k - $170k '\n",
       "                                     'Requirements: ETL/ELT, SQL, AWS/Google '\n",
       "                                     'Cloud, Linux/Unix, Spark (preferred), '\n",
       "                                     'NoSQL (preferred), Machine Learning '\n",
       "                                     'concepts (preferred) Based in beautiful '\n",
       "                                     'Alexandria, VA, we are one of the '\n",
       "                                     'hottest media analytics and software '\n",
       "                                     'start-ups in the DC area. Due to growth, '\n",
       "                                     'we are actively seeking to hire a Senior '\n",
       "                                     'Data Engineer to join our team. The '\n",
       "                                     'ideal candidate will have at least 5 '\n",
       "                                     'years of experience with data pipelines '\n",
       "                                     '(built with Python), ETL experience, a '\n",
       "                                     'strong SQL background, experience with '\n",
       "                                     'AWS or Google Cloud, and strong '\n",
       "                                     'Unix/Linux fundamentals. Any experience '\n",
       "                                     'with Spark, NoSQL, and Machine Learning '\n",
       "                                     'would be a huge plus. If this sounds '\n",
       "                                     'like you, please apply now or send your '\n",
       "                                     'resume to shiv.warrier@cybercoders.com! '\n",
       "                                     'What You Will Be Doing Lead design and '\n",
       "                                     'development of data pipelines Deliver '\n",
       "                                     'features on a cadence within an agile '\n",
       "                                     'framework Contribute to the definition '\n",
       "                                     'of user stories Collaborate with other '\n",
       "                                     'members of the team, including offshore, '\n",
       "                                     'on development integration Write unit '\n",
       "                                     'tests and maintain high code quality, '\n",
       "                                     'per both static code analysis team '\n",
       "                                     'standards Be available on a rotating '\n",
       "                                     'schedule for production issues What You '\n",
       "                                     'Need for this Position Must-Have BS in '\n",
       "                                     'Computer Science or equivalent 5+ years '\n",
       "                                     'of experience in software/data '\n",
       "                                     'engineering Expertise in ETL/ELT '\n",
       "                                     'techniques Expertise in SQL Experience '\n",
       "                                     'working with AWS or Google Cloud Strong '\n",
       "                                     'Unix/Linux fundamentals Nice To Have '\n",
       "                                     'Experience with data processing '\n",
       "                                     'frameworks e.g. Spark Experience with '\n",
       "                                     'NoSQL column-store databases Exposure to '\n",
       "                                     'machine learning concepts Exposure to ad '\n",
       "                                     \"tech concepts terminology What's In It \"\n",
       "                                     'for You Competitive salary with high '\n",
       "                                     'bonus potential Collaborative and '\n",
       "                                     'creative atmosphere, with inspired '\n",
       "                                     'leadership Career advancement '\n",
       "                                     'opportunities Recognition and reward for '\n",
       "                                     'outstanding performance Great medical, '\n",
       "                                     'dental; vision Insurance packages '\n",
       "                                     'Competitive 401K with company match to '\n",
       "                                     'plan for the long term Unlimited '\n",
       "                                     'paid-time-off Transportation benefits, '\n",
       "                                     'cell phone reimbursement Casual dress '\n",
       "                                     'all day, every day So, if you are a '\n",
       "                                     'Senior Data Engineer with experience, '\n",
       "                                     'please apply today! Email Your Resume In '\n",
       "                                     'Word To Looking forward to receiving '\n",
       "                                     'your resume through our website and '\n",
       "                                     'going over the position with you. '\n",
       "                                     'Clicking apply is the best way to apply, '\n",
       "                                     'but you may also: '\n",
       "                                     'Shiv.Warrier@CyberCoders.com Please do '\n",
       "                                     'NOT change the email subject line in any '\n",
       "                                     'way. You must keep the JobID: linkedin : '\n",
       "                                     'SW3-1639508 -- in the email subject line '\n",
       "                                     'for your application to be '\n",
       "                                     'considered.*** Shiv Warrier - Sr. '\n",
       "                                     'Executive Recruiter - CyberCoders '\n",
       "                                     'Applicants must be authorized to work in '\n",
       "                                     'the U.S. CyberCoders, Inc is proud to be '\n",
       "                                     'an Equal Opportunity Employer All '\n",
       "                                     'qualified applicants will receive '\n",
       "                                     'consideration for employment without '\n",
       "                                     'regard to race, color, religion, sex, '\n",
       "                                     'national origin, disability, protected '\n",
       "                                     'veteran status, or any other '\n",
       "                                     'characteristic protected by law. Your '\n",
       "                                     'Right to Work - In compliance with '\n",
       "                                     'federal law, all persons hired will be '\n",
       "                                     'required to verify identity and '\n",
       "                                     'eligibility to work in the United States '\n",
       "                                     'and to complete the required employment '\n",
       "                                     'eligibility verification document form '\n",
       "                                     'upon hire.\", \\'industries\\': \\'Broadcast '\n",
       "                                     \"Media', 'company': 'CyberCoders', \"\n",
       "                                     \"'education': 'bachelor degree', \"\n",
       "                                     \"'months_experience': 60.0, 'sal_high': \"\n",
       "                                     \"0, 'sal_low': 0, 'salary': 0, 'title': \"\n",
       "                                     \"'Senior Data Engineer', 'skills': \"\n",
       "                                     \"'NoSQL,Agile Methodology,Unit \"\n",
       "                                     'Testing,Data Processing,Unix,Data '\n",
       "                                     'Engineering,Linux,Python (Programming '\n",
       "                                     'Language),Apache Spark,Machine '\n",
       "                                     'Learning,Software Quality (SQA/SQC),SQL '\n",
       "                                     '(Programming Language),Data '\n",
       "                                     'Pipelines,Amazon Web Services,Static '\n",
       "                                     'Program Analysis,Extract Transform Load '\n",
       "                                     '(ETL),Executive Recruitment,Computer '\n",
       "                                     'Science,Google Cloud Platform (GCP),User '\n",
       "                                     \"Story,Leadership'}\"},\n",
       "              'score': 0.977007508,\n",
       "              'values': []}],\n",
       " 'namespace': 'description',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in match_res.matches:\n",
    "    a = {}\n",
    "    metadata = i['metadata']\n",
    "    res.append(eval(metadata['extras'])['skills'].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NoSQL',\n",
       "  'Agile Methodology',\n",
       "  'Unit Testing',\n",
       "  'Data Processing',\n",
       "  'Unix',\n",
       "  'Data Engineering',\n",
       "  'Linux',\n",
       "  'Python (Programming Language)',\n",
       "  'Apache Spark',\n",
       "  'Machine Learning',\n",
       "  'Software Quality (SQA/SQC)',\n",
       "  'SQL (Programming Language)',\n",
       "  'Data Pipelines',\n",
       "  'Amazon Web Services',\n",
       "  'Static Program Analysis',\n",
       "  'Extract Transform Load (ETL)',\n",
       "  'Executive Recruitment',\n",
       "  'Computer Science',\n",
       "  'Google Cloud Platform (GCP)',\n",
       "  'User Story',\n",
       "  'Leadership'],\n",
       " ['NoSQL',\n",
       "  'Agile Methodology',\n",
       "  'Unit Testing',\n",
       "  'Data Processing',\n",
       "  'Unix',\n",
       "  'Data Engineering',\n",
       "  'Linux',\n",
       "  'Python (Programming Language)',\n",
       "  'Apache Spark',\n",
       "  'Machine Learning',\n",
       "  'Software Quality (SQA/SQC)',\n",
       "  'SQL (Programming Language)',\n",
       "  'Data Pipelines',\n",
       "  'Amazon Web Services',\n",
       "  'Static Program Analysis',\n",
       "  'Extract Transform Load (ETL)',\n",
       "  'Executive Recruitment',\n",
       "  'Computer Science',\n",
       "  'Google Cloud Platform (GCP)',\n",
       "  'User Story',\n",
       "  'Leadership'],\n",
       " ['NoSQL',\n",
       "  'Agile Methodology',\n",
       "  'Unit Testing',\n",
       "  'Data Processing',\n",
       "  'Unix',\n",
       "  'Data Engineering',\n",
       "  'Linux',\n",
       "  'Python (Programming Language)',\n",
       "  'Apache Spark',\n",
       "  'Machine Learning',\n",
       "  'Software Quality (SQA/SQC)',\n",
       "  'SQL (Programming Language)',\n",
       "  'Data Pipelines',\n",
       "  'Amazon Web Services',\n",
       "  'Static Program Analysis',\n",
       "  'Extract Transform Load (ETL)',\n",
       "  'Executive Recruitment',\n",
       "  'Computer Science',\n",
       "  'Google Cloud Platform (GCP)',\n",
       "  'User Story',\n",
       "  'Leadership']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Extract Transform Load (ETL)', 'Executive Recruitment', 'Google Cloud Platform (GCP)', 'Data Processing', 'Unix', 'NoSQL', 'Leadership', 'Machine Learning', 'Apache Spark', 'Linux', 'Computer Science', 'SQL (Programming Language)', 'Amazon Web Services', 'Python (Programming Language)', 'Data Engineering', 'Static Program Analysis', 'Software Quality (SQA/SQC)', 'Agile Methodology', 'Unit Testing', 'User Story', 'Data Pipelines'}\n"
     ]
    }
   ],
   "source": [
    "common_skills = set(res[0])\n",
    "\n",
    "# Iterate over the rest of the lists and find common elements\n",
    "for skills in res[1:]:\n",
    "    common_skills = common_skills.intersection(set(skills))\n",
    "\n",
    "print(common_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Extract Transform Load (ETL)', 'Executive Recruitment', 'Google Cloud Platform (GCP)', 'Data Processing', 'Unix', 'NoSQL', 'Leadership', 'Machine Learning', 'Apache Spark', 'Linux', 'Computer Science', 'SQL (Programming Language)', 'Amazon Web Services', 'Python (Programming Language)', 'Data Engineering', 'Static Program Analysis', 'Software Quality (SQA/SQC)', 'Agile Methodology', 'Unit Testing', 'User Story', 'Data Pipelines'}\n"
     ]
    }
   ],
   "source": [
    "common_skills = set(res[0])\n",
    "\n",
    "# Iterate over the rest of the lists and find common elements\n",
    "for skills in res[1:]:\n",
    "    common_skills = common_skills.union(set(skills))\n",
    "\n",
    "print(common_skills)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
